n_sd, percentile, seed){
q1_clean <- outlier_remove_df(whichq,col_name,n_sd,percentile)
q2_clean <- outlier_remove_df(whichdo,col_name,n_sd,percentile)
full_bm <- mean(q1_clean[[col_name]], na.rm=T)
if (sum(!is.na(q2_clean[[col_name]]))==0){
cat("Not enough Data for One Sample t-test", "\n")
cat("\n")
# use -1 to indicate not enough data for one sample t-test
if(seed==123){
pvalue_123 <<- c(pvalue_123, -1)
} else if(seed==1234){
pvalue_1234 <<- c(pvalue_1234, -1)
} else if(seed==12345){
pvalue_12345 <<- c(pvalue_12345, -1)
}
} else if (sum(!is.na(q2_clean[[col_name]]))<2){
cat("Only 1 data point", "\n")
cat("\n")
# use -1 to indicate not enough data for one sample t-test
if(seed==123){
pvalue_123 <<- c(pvalue_123, -2)
} else if(seed==1234){
pvalue_1234 <<- c(pvalue_1234, -2)
} else if(seed==12345){
pvalue_12345 <<- c(pvalue_12345, -2)
}
} else if (length(unique(q2_clean[[col_name]])) %in% c(1,2)){
cat("All data constant", "\n")
cat("\n")
# use -1 to indicate not enough data for one sample t-test
if(seed==123){
pvalue_123 <<- c(pvalue_123, -3)
} else if(seed==1234){
pvalue_1234 <<- c(pvalue_1234, -3)
} else if(seed==12345){
pvalue_12345 <<- c(pvalue_12345, -3)
}
} else {
result <- t.test(q2_clean[[col_name]], mu=full_bm)
if(seed==123){
pvalue_123 <<- c(pvalue_123, result$p.value)
} else if(seed==1234){
pvalue_1234 <<- c(pvalue_1234, result$p.value)
} else if(seed==12345){
pvalue_12345 <<- c(pvalue_12345, result$p.value)
}
print(result)
}
}
# Function to do benchmark comparison for questions
compare_benchmark <- function(qdf, df, col_name, seed){
qdf_name <- deparse(substitute(qdf))
df_name <- deparse(substitute(df))
outlier_remove_summary(qdf,col_name,3,0.99,qdf_name,0)
outlier_remove_summary(df,col_name,3,0.99,df_name,seed)
outlier_remove_ttest(qdf,df,col_name,3,0.99,seed)
}
mae <- function(l1, l2){
ab_error <- abs(l1-l2)
mae_out <- mean(ab_error)
return (mae_out)
}
mse <- function(l1, l2){
sq_error <- (l1-l2)**2
mse_out <- mean(sq_error)
return (mse_out)
}
rmse <- function(l1, l2){
sq_error <- (l1-l2)**2
rmse_out <- sqrt(mean(sq_error))
return (rmse_out)
}
benchmark_questions <- c("C1b.r", "Total_Expenditure", "Hotel_exp.r", "c4d_4.r", "c4d_5.r", "c4d_6.r", "c6c_1.r", "c6c_2.r", "c6c_3.r", "C7b.r", "c10c_1.r", "c10c_2.r", "c10c_3.r", "c12c_2.r", "c12c_6.r", "c12c_7.r", "C14.r")
healthcare_benchmark_questions <- c("c12c_2.r", "c12c_6.r")
means_df <- data.frame(col_name = benchmark_questions)
mean_full <- c()
benchmark_ci_left <- c()
benchmark_ci_right <- c()
mean_123 <- c()
pvalue_123 <- c()
mean_1234 <- c()
pvalue_1234 <- c()
mean_12345 <- c()
pvalue_12345 <- c()
qdata <- read.csv("OVS_Data/MeanimputedData.csv")%>%filter(Quarter=="16Q1")
collatedMicroResults <- read.csv("Stitch/finalresultk80median.csv")
seed <- 123
for (qn in benchmark_questions) {
compare_benchmark(qdata,collatedMicroResults,qn,seed)
}
cat("Number of benchmarks Similar:",sum(pvalue_123>0.05),"\n")
cat("Number of benchmarks", length(benchmark_questions),"\n")
cat("Percentage Similar", sum(pvalue_123>0.05)/length(benchmark_questions),"\n")
mae(mean_full,mean_123)
mse(mean_full,mean_123)
rmse(mean_full,mean_123)
mean_123
mean_full
cat("Benchmark not similar:",benchmark_questions[which(pvalue_123<0.05)],"\n")
cat("Benchmark not similar (Index):", which(pvalue_123<0.05))
cat("Sum of Benchmarks within CI:",sum(mean_123>=benchmark_ci_left & mean_123<=benchmark_ci_right),"\n")
cat("Percentage within CI:", sum(mean_123>=benchmark_ci_left & mean_123<=benchmark_ci_right)/17*100)
cat("Sum of Benchmarks outside CI:",17-sum(mean_123>=benchmark_ci_left & mean_123<=benchmark_ci_right),"\n")
cat("Which Benchmarks outside CI:", benchmark_questions[c(1:17)[-which(mean_123>=benchmark_ci_left & mean_123<=benchmark_ci_right)]])
install.packages(c("metafor", "meta"))
plot(cars)
library(metafor)
library(meta)
dat=read.csv("vr_race.csv",header=T,sep=",")
dat=read.csv("vr_race.csv",header=T,sep=",")
ies=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
dat=read.csv("vr_race.csv",header=T,sep=",")
ies=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
dat=read.csv("vr_race.csv",header=T,sep=",")
ies=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes/pes.logit/pes.da=rma(yi,vi,data=ies,method="DL")
dat=read.csv("vr_race.csv",header=T,sep=",")
ies=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes/pes.logit/pes.da=rma(yi,vi,data=ies,method="DL")
dat=read.csv("vr_race.csv",header=T,sep=",")
ies=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes.logit=rma(yi,vi,data=ies,method="DL")
#random effects using the DerSimonian-Laird estimator
dat=read.csv("vr_race.csv",header=T,sep=",")
ies=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes.logit=rma(yi,vi,data=ies,method="DL")
#random effects using the DerSimonian-Laird estimator
pes=predict(pes.logit, transf=transf.ilogit)
dat=read.csv("vr_race.csv",header=T,sep=",")
ies=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes.logit=rma(yi,vi,data=ies,method="DL")
#random effects using the DerSimonian-Laird estimator
pes=predict(pes.logit, transf=transf.ilogit)
dat=read.csv("vr_race.csv",header=T,sep=",")
ies=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes.logit=rma(yi,vi,data=ies,method="DL")
#random effects using the DerSimonian-Laird estimator
pes=predict(pes.logit, transf=transf.ilogit)
print(pes)
dat=read.csv("vr_race.csv",header=T,sep=",")
ies.logit=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes.logit=rma(yi,vi,data=ies,method="DL")
#random effects using the DerSimonian-Laird estimator
pes=predict(pes.logit, transf=transf.ilogit)
print(pes)
dat=read.csv("vr_race.csv",header=T,sep=",")
ies.logit=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes.logit=rma(yi,vi,data=ies,method="DL")
#random effects using the DerSimonian-Laird estimator
pes=predict(pes.logit, transf=transf.ilogit)
print(pes)
library(metafor)
library(meta)
dat=read.csv("vr_race.csv",header=T,sep=",")
ies.logit=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes.logit=rma(yi,vi,data=ies.logit,method="DL",level=95)
#random effects using the DerSimonian-Laird estimator
pes=predict(pes.logit, transf=transf.ilogit)
print(pes)
library(metafor)
library(meta)
dat=read.csv("vr_race.csv",header=T,sep=",")
ies.logit=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes.logit=rma(yi,vi,data=ies.logit,method="DL",level=95)
#random effects using the DerSimonian-Laird estimator
pes=predict(pes.logit, transf=transf.ilogit)
print(pes,digits=6)
dat=read.csv("vr_race.csv",header=T,sep=",")
ies.logit=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes.logit=rma(yi,vi,data=ies.logit,method="DL",level=95)
#random effects using the DerSimonian-Laird estimator
pes=predict(pes.logit, transf=transf.ilogit)
print(pes)
print(pes.logit)
confint(pes.logit)
pes.summary=metaprop(cases,total,authoryear,data=dat,sm="PLO")
forest(pes.summary)
library(metafor)
library(meta)
dat=read.csv("vr_race.csv",header=T,sep=",")
ies.logit=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes.logit=rma(yi,vi,data=ies.logit,method="DL",level=95)
#random effects using the DerSimonian-Laird estimator
pes=predict(pes.logit, transf=transf.ilogit)
print(pes)
print(pes.logit)
confint(pes.logit)
pes.summary=metaprop(cases,total,authoryear,data=dat,sm="PLO",method.tau="DL",method.ci="NAsm")
forest(pes.summary,xlim=c(0,4),pscale=1000,rightcols=FALSE,leftcols=c("studlab","event","n","effect","ci"),leftlabs=c("Study","Cases","Total","Prevalence","95% C.I."),smlab="",weight.study="random",squaresize=0.5,col.square="navy",col.square.lines="navy",col.diamond="maroon",col.diamond.lines="maroon",pooled.totals=FALSE,comb.fixed=FALSE,fs.hetstat=10,print.tau2=TRUE,print.Q=TRUE,print.I2=TRUE)
pes.summary=metaprop(cases,total,authoryear,data=dat,sm="PLO",method.tau="DL",method.ci="NAsm")
forest(pes.summary)
pes.summary=metaprop(cases,total,authoryear,data=dat,sm="PLO",method.tau="DL",method.ci="NAsm")
forest(pes.summary,weight.study="random")
library(metafor)
library(meta)
dat=read.csv("vr_race.csv",header=T,sep=",")
ies.logit=escalc(xi=cases, ni=total, data=dat, measure="PLO")
#PLO is the logit transformation
pes.logit=rma(yi,vi,data=ies.logit,method="DL",level=95)
#random effects using the DerSimonian-Laird estimator
pes=predict(pes.logit, transf=transf.ilogit)
print(pes)
print(pes.logit)
confint(pes.logit)
pes.summary=metaprop(cases,total,authoryear,data=dat,sm="PLO",method.tau="DL",method.ci="NAsm")
forest(pes.summary,weight.study="random")
pes.summary=metaprop(cases,total,authoryear,data=dat,sm="PLO",method.tau="DL",method.ci="NAsm")
forest(pes.summary,weight.study="random",comb.fixed="FALSE")
pes.summary=metaprop(cases,total,authoryear,data=dat,sm="PLO",method.tau="DL",method.ci="NAsm")
forest(pes.summary,weight.study="random",comb.fixed=FALSE)
my_data <- read.csv('t_test.csv')
my_data <- read.csv('t_test.csv')
x <- my_data[1]
#t.test(x, y, alternative = "two.sided", var.equal = FALSE)
View(x)
View(x)
my_data <- read.csv('t_test.csv')
x <- my_data[1]
print(x)
#t.test(x, y, alternative = "two.sided", var.equal = FALSE)
my_data <- read.csv('t_test.csv')
x <- my_data[1]
print(x)
#t.test(x, y, alternative = "two.sided", var.equal = FALSE)
my_data <- read.csv('t_test.csv')
x <- my_data[1]
print(x)
#t.test(x, y, alternative = "two.sided", var.equal = FALSE)
my_data <- read.csv('t_test.csv')
x <- my_data[1]
print(x)
#t.test(x, y, alternative = "two.sided", var.equal = FALSE)
my_data <- read.csv('t_test.csv')
x <- my_data[1]
#print(x)
y <- my_data[2]
#t.test(x, y, alternative = "two.sided", var.equal = FALSE)
my_data <- read.csv('t_test.csv')
x <- my_data[1]
#print(x)
y <- my_data[2]
print(y)
#t.test(x, y, alternative = "two.sided", var.equal = FALSE)
my_data <- read.csv('t_test.csv')
x <- my_data[1]
#print(x)
y <- my_data[2]
#print(y)
t.test(x, y, alternative = "two.sided", var.equal = FALSE)
my_data <- read.csv('t_test.csv')
x <- my_data[1]
#print(x)
y <- my_data[2]
#print(y)
t.test(x, y, alternative = "two.sided", var.equal = FALSE)
res <- prop.test(x = c(91, 94), n = c(136, 136))
# Printing the results
res
res <- prop.test(x = c(90, 87), n = c(136, 136))
# Printing the results
res
res <- prop.test(x = c(6, 7), n = c(8, 8))
# Printing the results
res
res <- prop.test(x = c(6, 7), n = c(8, 8),correct = FALSE)
# Printing the results
res
x<- c(0.3234125,0.25215,0.2573127,0.2634103,
0.2784152,0.2710858,0.2941074,0.2518255)
# KLD Median MTL
y <- c(0.3504664,0.2663471,0.2569721,0.2526354,
0.29204,0.2888421,0.3032604,0.2809752)
res2<-t.test(x, y, paired = TRUE, alternative = "two.sided")
res2
# KLD Mean MTL
x<- c(0.3234125,0.25215,0.2573127,0.2634103,
0.2784152,0.2710858,0.2941074,0.2518255)
# KLD Median MTL
y <- c(0.3504664,0.2663471,0.2569721,0.2526354,
0.29204,0.2888421,0.3032604,0.2809752)
res2<-t.test(x, y, paired = FALSE, alternative = "two.sided")
res2
# KLD Mean MTL
x<- c(0.3234125,0.25215,0.2573127,0.2634103,
0.2784152,0.2710858,0.2941074,0.2518255)
# KLD Median MTL
y <- c(0.3504664,0.2663471,0.2569721,0.2526354,
0.29204,0.2888421,0.3032604,0.2809752)
res2<-t.test(x, y, paired = FALSE, alternative = "two.sided")
res2
x <- c(71,71,65,59,65,59,53,65)
y <- c(82,76,71,65,71,82,53,76)
res3<-t.test(x, y, paired = FALSE, alternative = "less")
res3
x <- c(71,71,65,59,65,59,53,65)
y <- c(82,76,71,65,71,82,53,76)
res3<-t.test(x, y, paired = FALSE, alternative = "less")
res3
x <- c(71,71,65,59,65,59,53,65)
y <- c(82,76,71,65,71,82,53,76)
res3<-t.test(x, y, paired = FALSE, alternative = "greater")
res3
x <- c(71,71,65,59,65,59,53,65)
y <- c(82,76,71,65,71,82,53,76)
res3<-t.test(x, y, paired = FALSE, alternative = "less")
res3
x <- c(71,71,65,59,65,59,53,65)
y <- c(82,76,71,65,71,82,53,76)
res3<-t.test(x, y, paired = TRUE, alternative = "less")
res3
x <- c(71,71,65,59,65,59,53,65)
y <- c(82,76,71,65,71,82,53,76)
res3<-t.test(x, y, paired = FALSE, alternative = "less")
res3
res <- prop.test(x = c(9, 2,6), n = c(9, 9,9),correct = FALSE)
# Printing the results
res
res <- prop.test(x = c(26, 4,21), n = c(27, 27,27),correct = TRUE)
# Printing the results
res
res <- prop.test(x = c(26, 4,21), n = c(27, 27,27),correct = TRUE)
# Printing the results
res
res <- prop.test(x = c(26, 4,21), n = c(27, 27,27),correct = FALSE)
# Printing the results
res
res <- prop.test(x = c(26, 4,21), n = c(27, 27,27),correct = FALSE)
# Printing the results
res
res <- prop.test(x = c(26, 4,21), n = c(27, 27,27),correct = FALSE)
# Printing the results
res
res <- prop.test(x = c(26, 4,21), n = c(27, 27,27),correct = FALSE)
# Printing the results
res
res <- prop.test(x = c(26, 4,21), n = c(27, 27,27),correct = FALSE)
# Printing the results
res
res <- prop.test(x = c(26,21), n = c(27,27),correct = FALSE)
# Printing the results
res
res <- prop.test(x = c(26,21), n = c(27,27),correct = TRUE)
# Printing the results
res
res <- prop.test(x = c(26,21), n = c(27,27),correct = FALSE)
# Printing the results
res
res <- prop.test(x = c(26,21), n = c(27,27),correct = FALSE,alternative='less')
# Printing the results
res
res <- prop.test(x = c(26,21), n = c(27,27),correct = FALSE,alternative='greater')
# Printing the results
res
res <- prop.test(x = c(26,21), n = c(27,27),correct = FALSE)
# Printing the results
res
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
setwd("~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye")
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
# loading R package TDA
library(package="TDA")
increasedlist <- read.csv('blinked.csv')
totaln <- nrow(increasedlist)
print(totaln)
# loading R package TDA
library(package="TDA")
increasedlist <- read.csv('blinked.csv')
totaln <- nrow(increasedlist)
print(totaln)
#14931
#80% train
trainnum <- 11945
testnum <- 2986
print(trainnum+testnum)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
# loading R package TDA
library(package="TDA")
increasedlist <- read.csv('blinked.csv')
totaln <- nrow(increasedlist)
print(totaln)
# loading R package TDA
library(package="TDA")
increasedlist <- read.csv('blinked.csv')
totaln <- nrow(increasedlist)
print(totaln)
#1493
#80% train
trainnum <- 1195
testnum <- 298
print(trainnum+testnum)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
# loading R package TDA
library(package="TDA")
increasedlist <- read.csv('blinked.csv')
totaln <- nrow(increasedlist)
print(totaln)
#1493
# loading R package TDA
library(package="TDA")
increasedlist <- read.csv('blinked.csv')
totaln <- nrow(increasedlist)
print(totaln)
#1496
#80% train
trainnum <- 1198
testnum <- 298
print(trainnum+testnum)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Eye/TDA_distmatrix_v2.R', echo=TRUE)
# loading R package TDA
library(package="TDA")
prefix <- 'datatraining'
increasedlist <- read.csv(paste0(prefix,'occupied.csv'))
totaln <- nrow(increasedlist)
print(totaln)
setwd("~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy")
# loading R package TDA
library(package="TDA")
prefix <- 'datatraining'
increasedlist <- read.csv(paste0(prefix,'occupied.csv'))
totaln <- nrow(increasedlist)
print(totaln)
# loading R package TDA
library(package="TDA")
prefix <- 'datatraining'
increasedlist <- read.csv(paste0(prefix,'occupied.csv'))
totaln <- nrow(increasedlist)
print(totaln)
#813
#80% train
trainnum <- 650
testnum <- 163
print(trainnum+testnum)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy/TDA_distmatrix_v3.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy/TDA_distmatrix_v3.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy/TDA_distmatrix_v3.R', echo=TRUE)
# loading R package TDA
library(package="TDA")
prefix <- 'datatraining'
increasedlist <- read.csv(paste0(prefix,'occupied.csv'))
totaln <- nrow(increasedlist)
print(totaln)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy/TDA_distmatrix_v3.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy/TDA_distmatrix_v3.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy/TDA_distmatrix_v3.R', echo=TRUE)
# loading R package TDA
library(package="TDA")
prefix <- 'datatraining'
increasedlist <- read.csv(paste0(prefix,'occupied.csv'))
totaln <- nrow(increasedlist)
print(totaln)
setwd("~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter")
# loading R package TDA
library(package="TDA")
prefix <- 'datatraining'
increasedlist <- read.csv(paste0(prefix,'occupied.csv'))
totaln <- nrow(increasedlist)
print(totaln)
# loading R package TDA
library(package="TDA")
prefix <- 'datafull'
increasedlist <- read.csv(paste0(prefix,'occupied.csv'))
totaln <- nrow(increasedlist)
print(totaln)
# loading R package TDA
library(package="TDA")
prefix <- 'datafull'
increasedlist <- read.csv(paste0(prefix,'occupied.csv'))
totaln <- nrow(increasedlist)
print(totaln)
#1000
#80% train
trainnum <- 800
testnum <- 200
print(trainnum+testnum)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
setwd("~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter")
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestAfter/TDA_distmatrix_v4.R', echo=TRUE)
setwd("~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestBefore")
source('~/Desktop/!yuan/!Research Fellow/!TopologyStock/Occupancy_TestBefore/TDA_distmatrix_v4.R', echo=TRUE)
